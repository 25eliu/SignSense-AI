# SignSense-AI
## **Overview**
Over 500,000 people across the US and Canada use American Sign Language (ASL) as their primary form of communication. This deep learning model is designed to convert ASL FingerSpelling to Text, facilitating more efficient communication for ASL users when interacting with others.

## **Dataset**
The dataset used in this project was obtained from the Kaggle competition called "ASL FingerSpelling," which can be found at the following link: ASL FingerSpelling Kaggle Competition. The dataset provides a valuable resource for training and evaluating the performance of our model.

## **Pre-processing**
To prepare the data for training, we utilized MediaPipe, a popular deep-learning framework for processing multimedia data. MediaPipe helped us extract relevant features and information from the ASL FingerSpelling dataset, ensuring that the input to our model was formatted correctly for effective learning.

## **Model**
We implemented our deep learning model using TensorFlow, a powerful and widely-used open-source machine learning library. We took inspiration from the following Kaggle notebook by Gusthema, which significantly contributed to the foundation of our work: ASL Fingerspelling Recognition with TensorFlow.

## **Post-processing**
The post-processing step, which is crucial for refining the output of our model, was made possible by leveraging the capabilities of GPT-3.5. This advanced language model helped us fine-tune and improve the text conversion accuracy, ensuring smoother and more accurate communication for ASL users.

## **Project Development**
This ASL FingerSpelling to Text deep learning model was developed as part of the UCSC Cosmos 2023 program. The collaboration and dedication of the team members made this project a reality, and we are proud to contribute to enhancing communication accessibility for the ASL community.
